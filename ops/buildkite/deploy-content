#!/bin/bash
#
#  deploy-content
#
#  Bake content and deploy to Cloudflare Pages.
#

set -o errexit
set -o pipefail
set -o nounset


# Cloudflare Pages project name
PROJECT_NAME=owid

# URL of Cloudflare page
# branches would be deployed to https://[branch].$PROJECT_NAME.pages.dev/"
# BAKED_BASE_URL="https://$PROJECT_NAME.pages.dev"
# BAKED_BASE_URL="https://pages.owid.io"
BAKED_BASE_URL="https://ourworldindata.org"

deploy_content () {
    echo "--- Deploying content to Cloudflare"

    if [[ "$BRANCH" != "master" ]]; then
        echo "Error: You're not on the master branch. Exiting."
        exit 1
    fi

    # NOTE: in theory we could run lightning bake in parallel to regular bake and only lock `deploy_to_cloudflare`
    # right now lightning bake has to wait if there's a regular bake
    if [ -n "${LIGHTNING_GDOC_SLUGS:-}" ]; then
        bake_gdoc_posts "$LIGHTNING_GDOC_SLUGS"
    # Lightning updates for charts
    elif [ -n "${LIGHTNING_CHART_SLUGS:-}" ]; then
        bake_charts "$LIGHTNING_CHART_SLUGS"
        # We could only sync selected slugs, but syncing everything takes only 6s anyway
        sync_to_r2_aws grapher/exports
    else
        update_owid_content_repo
        sync_wordpress_uploads
        bake_site
        sync_baked_data_to_r2
    fi

    create_dist
    deploy_to_cloudflare

    echo "--- Site deployed to $BAKED_BASE_URL"
}


update_owid_content_repo() {
    echo '--- Updating owid-content'
    (
        cd owid-content
        git fetch --all -q
        git checkout master -q
        git reset --hard origin/master
    )
}

sync_wordpress_uploads() {
    echo '--- Syncing live-wordpress uploads from owid-live'

    # see owid-grapher/.../download-wordpress-uploads.sh
    # this takes about 3 minutes
    rsync -havzq --delete \
        --rsh 'ssh -o StrictHostKeyChecking=no' \
        --exclude='/.gitkeep' \
        owid@live.owid.io:live-data/wordpress/uploads/ wordpress/web/app/uploads
}


sync_to_s3_aws() {
    local target=$1
    echo "--- Syncing ${target}..."
    aws --endpoint=https://nyc3.digitaloceanspaces.com s3 sync live-data/bakedSite/${target} s3://owid-catalog/bake/cloudflare-pages/${target} --acl public-read
}

sync_to_s3_rclone() {
    local target=$1
    echo "--- Syncing ${target}..."
    rclone sync live-data/bakedSite/${target} spaces-nyc3:owid-catalog/bake/cloudflare-pages/${target} --checkers=64 --ignore-checksum
}

sync_to_r2_rclone() {
    local target=$1
    echo "--- Syncing ${target}..."
    rclone sync live-data/bakedSite/${target} r2:owid-assets/${target} --checkers=64 --ignore-checksum
}

sync_to_r2_aws() {
    local target=$1
    echo "--- Syncing ${target}..."
    R2_ENDPOINT_URL=$(grep 'R2_ENDPOINT_URL=' owid-grapher/.env | cut -d '=' -f 2-)
    aws --profile r2 --endpoint-url "${R2_ENDPOINT_URL}" s3 sync live-data/bakedSite/${target} s3://owid-assets/${target} --acl public-read
}

sync_baked_data_to_s3() {
    echo '--- Sync baked data to S3'
    # Cloudflare Pages has limit of 20000 files
    sync_to_s3_aws grapher/exports  # 9203 files
    sync_to_s3_aws exports  # 3314 files
    sync_to_s3_aws uploads  # 20609 files
}

sync_baked_data_to_r2() {
    echo '--- Sync baked data to R2'
    # Cloudflare Pages has limit of 20000 files
    # TODO: There's also images/published, which are the gdocs images synced from GDrive.
    #   There's currently a small-enough amount of them, but we need to sync them to R2 or Cloudflare Images at some point.
    # NOTE: aws is about 3x faster than rclone
    sync_to_r2_aws grapher/exports  # 9203 files
    sync_to_r2_aws exports  # 3314 files
    sync_to_r2_aws uploads  # 20609 files
}

deploy_to_cloudflare() {
    (
        echo '--- Deploy to Cloudflare'
        # wrangler uses CLOUDFLARE_ACCOUNT_ID and CLOUDFLARE_API_TOKEN from owid-grapher/.env, see the token
        # at https://dash.cloudflare.com/profile/api-tokens
        # for branch-specific non-production deploys, use `--branch master`
        cd dist
        # trim \r, they remove previous logs in buildkite
        env $(grep "^CLOUDFLARE" ../owid-grapher/.env | xargs -0) npx wrangler pages deploy . --project-name "$PROJECT_NAME" 2>&1 | tr -d '\r'
    )
}

create_dist() {
    echo '--- Creating dist/ folder'
    # Define a list of excluded directories for rsync
    EXCLUDES=(grapher/data/variables/ .git/ grapher/exports/ exports/ uploads/)

    # Build rsync command with excluded directories
    RSYNC_COMMAND=("rsync" "-havzq" "--delete")
    for EXCLUDE in "${EXCLUDES[@]}"; do
        RSYNC_COMMAND+=("--exclude=$EXCLUDE")
    done

    "${RSYNC_COMMAND[@]}" live-data/bakedSite/ dist/

    # remove .etag of gdoc images from dist
    rm dist/images/published/*.etag

    # copy over Pages Functions as-is
    rsync -havzq --delete owid-grapher/functions dist/

    # we need node_modules for Pages Functions
    rm -rf dist/node_modules
    cp -rL owid-grapher/node_modules dist/ # the `L` flag copies over symlinked files, too, which we need for @ourworldindata/utils etc.

    cp owid-grapher/_routes.json dist/_routes.json
}


bake_site() {
    echo '--- Baking site to ~/live-data/bakedSite'

    (
        cd owid-grapher

        yarn buildTsc
        mkdir -p /home/owid/live-data/bakedSite/grapher
        yarn buildLocalBake $BAKED_BASE_URL /home/owid/live-data/bakedSite
    )
}

bake_gdoc_posts() {
    local slugs="$1"
    echo "--- Baking GDoc posts ${slugs}"
    (
        cd owid-grapher
        yarn bakeGdocPosts --slugs ${slugs}
    )
}

bake_charts() {
    local slugs="$1"
    echo "--- Baking Charts ${slugs}"
    (
        cd owid-grapher
        yarn bakeCharts --slugs ${slugs}
    )
}

deploy_content